{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a20c7b0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_postgres import PGVector\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain.tools import tool\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import getpass\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "13dfaaa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.environ.get(\"GOOGLE_API_KEY\"):\n",
    "  print(\"Please set the GOOGLE_API_KEY environment variable.\")\n",
    "\n",
    "model = init_chat_model(\"google_genai:gemini-2.5-flash\")\n",
    "\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/gemini-embedding-001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "806a731d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.environ.get(\"SUPABASE_CONNECTION_STRING\"):\n",
    "    print(\"Please set the SUPABASE_CONNECTION_STRING environment variable.\")\n",
    "\n",
    "vector_store = PGVector(\n",
    "    embeddings=embeddings,\n",
    "    collection_name=\"lilianweng_blog\",\n",
    "    connection=os.environ[\"SUPABASE_CONNECTION_STRING\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e934f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool(response_format=\"content_and_artifact\")\n",
    "def retrieve_context(query: str):\n",
    "    \"\"\"Retrieve information to help answer a query.\"\"\"\n",
    "    retrieved_docs = vector_store.similarity_search(query, k=2)\n",
    "    serialized = \"\\n\\n\".join(\n",
    "        (f\"Source: {doc.metadata}\\nContent: {doc.page_content}\")\n",
    "        for doc in retrieved_docs\n",
    "    )\n",
    "    return serialized, retrieved_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3d9012ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "\n",
    "\n",
    "tools = [retrieve_context]\n",
    "# If desired, specify custom instructions\n",
    "prompt = (\n",
    "    \"You have access to a tool that retrieves context from a blog post. \"\n",
    "    \"Use the tool to help answer user queries.\"\n",
    ")\n",
    "agent = create_agent(model, tools, system_prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "69c6fdfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What are some challenges and limitations when building LLM based Agnets.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  retrieve_context (10cd204e-23a4-42d4-8192-19cb19cc8ac4)\n",
      " Call ID: 10cd204e-23a4-42d4-8192-19cb19cc8ac4\n",
      "  Args:\n",
      "    query: challenges and limitations when building LLM based Agents\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: retrieve_context\n",
      "\n",
      "\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  retrieve_context (415e41b9-b70c-4ec6-9462-3fac32c3d82f)\n",
      " Call ID: 415e41b9-b70c-4ec6-9462-3fac32c3d82f\n",
      "  Args:\n",
      "    query: LLM based Agents\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: retrieve_context\n",
      "\n",
      "\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  retrieve_context (45b63913-d7ad-4072-9d66-1f61005e9d85)\n",
      " Call ID: 45b63913-d7ad-4072-9d66-1f61005e9d85\n",
      "  Args:\n",
      "    query: challenges building AI agents\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: retrieve_context\n",
      "\n",
      "\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[{'type': 'text', 'text': 'I am sorry, but I could not find any information regarding the challenges and limitations when building LLM-based agents in the available context.', 'extras': {'signature': 'CsoEAXLI2ny9zwUJKjXWIura31TYhQ70zKZGCxagbujPsEFoN6XNs/kgs36vlii5MPWrylcxAce3wnpvRaK9Iz5qFWhbTpc7vprPgfOl3ZyioICfPmmCvssLzc1CI8T5XCG7JGQ8715+6rl3KxleUjdNjyjaNQT6Yn3tn47Bidteu3hkMfd7Pj/eZEjnvtc3Uxcs3vKxt194SPpA7GV9aS+o72SNOdZzSKhOo+dCLk7poW0i3PlZieJm0F0b9x4NUcbbV6yqpC9Mn8dzJDbHTkP4wifItJG2aX+DrP+eP/0P/erE/TYs7WBO99x7L2BqOSIcmtIBBRYdwoxasRYQj7jhB+32B0wDcI8TDt/ni+rdT9TqtZoe7Hqf27g61LI87FlSrTpSy8NKlafUk0iigwX539/1v25OuIqIv7pFPKaQQ0MPkFcLW/JDBVJK0MQrbJ6eZjbiMlwz1W38C+W1uL6XUANbrFuxv28Y8erRptZ8C0sPpdb3k91SOv51WMetUxJlG88sLQlBMnlX1jiaxw1/G70k8ZOpZv4YNCFdTRt0gaahluLr/r5Pr93TiUaJBcEBzX9gdx23NnwK7/OZP9Gj+3AEEnvIaHxxuW6NM+85R838ZKG2fSCJgcO2t2ZCKfiRrAuRoMRwDT+UHlViyxu3y5OO5xca3lnPxAl5TajklZndskRQbrWlhR8k9szejsDk6HDqk5X3U16DPDobhaEHjh60sT/Crz/jT5jWASTW4qq4Qf9Yeb5ZF7P3rw+tg1Nf5Mrt4QMMEb7jkQ=='}}]\n"
     ]
    }
   ],
   "source": [
    "query = (\n",
    "    \"What are some challenges and limitations when building LLM based Agnets.\"\n",
    ")\n",
    "\n",
    "for event in agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": query}]},\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    last_message = event[\"messages\"][-1]\n",
    "    last_message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2d790723",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "I am sorry, but I could not find any information regarding the challenges and limitations when building LLM-based agents in the available context."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Render the agent's last message as Markdown in the Jupyter output\n",
    "from IPython.display import Markdown, display\n",
    "display(Markdown(last_message.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c382ee12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hai5016-rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
